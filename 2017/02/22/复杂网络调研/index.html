<!DOCTYPE HTML>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="google-site-verification" content="" />
  
  <title>复杂网络调研</title>
  <meta name="author" content="She Song">
   <meta name="description" content="This is She Song&#39;s blog, I&#39;m interested in Distributed Computing and Machine Learning.">
  

  <meta property="og:title" content="复杂网络调研"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:site_name" content="Song&#39;s blog"/>
 <meta property="og:image" content="undefined"/>
  
  <link href="/apple-touch-icon-precomposed.png" sizes="180x180" rel="apple-touch-icon-precomposed">
  <link rel="alternate" href="true" title="Song&#39;s blog" type="application/atom+xml">
  <link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.6/css/bootstrap.min.css">
  <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/m.min.css">
  <link rel="icon" type="image/x-icon" href="/favicon.ico"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><a id="top"></a>
  <div id='wx_pic' style='display:none;'><img src='/wx_share.png'/></div>
  <div id="main">
    <div class="behind">
      <div class="back">
        <a href="/" class="black-color"><i class="fa fa-times" aria-hidden="true"></i></a>
      </div>
      <div class="description">
        &nbsp;Easy words so hard to say
      </div>
    </div>
    <div class="container">
      

  <article class="standard post">
    <div class="title">
      
  
    <h1 class="page-title center">
        复杂网络调研
    </h1>
  


    </div>
    <div class="meta center">
      
<time datetime="2017-02-22T03:10:08.000Z">
  <i class="fa fa-calendar"></i>&nbsp;
  2017-02-22
</time>



    
    &nbsp;
    <i class="fa fa-tag"></i>&nbsp;
    <a href="/categories/Complex-Network/">Complex Network</a>




    
    &nbsp;
    <i class="fa fa-tag"></i>&nbsp;
    <a href="/tags/调研/">调研</a>


    </div>
    <hr>
    <div class="picture-container">
      
    </div>
    <h1 id="model-network-topology-1">1 Model (Network Topology) [1]</h1>
<h2 id="regular-network">1.1 Regular Network</h2>
<ul>
<li>全局耦合网络(globally coupled network): 任意两个点之间都有边直接相连</li>
<li>最近邻耦合网络(nearest-neighbor coupled network): 其中的每一个节点只和周围的邻居节点相邻</li>
<li>星形耦合网络(star coupled network): 只有一个中心点，其余的 N-1个点都只与这个中心点连接，而它们彼此之间不连接</li>
</ul>
<h2 id="random-network">1.2 Random Network</h2>
<p>随机图中两个节点之间不论是否具有共同的邻居节点，其连接概率为 <span class="math inline">\(p\)</span>。由于每条边的出现与否都是独立的，随即图的度分布可用 Possion 分布 [3] 来表示 <span class="math display">\[ P(k)=\binom{n}{k}p^{k}(1-p)^{N-k}\approx \frac{\left\langle k\right\rangle^k e^{-\left\langle k\right\rangle} }{k!} \]</span></p>
<h2 id="small-world-network">1.3 Small-World Network</h2>
<p>小世界网络作为从完全规则网络向完全随即图的过度，人们提出多种小世界模型，其中著名的有WS小世界模型 [4]和NW小世界模型 [3]。WS小世界模型是在该过度过程中随机化重连边，而NW小世界模型这是随机化加边。</p>
<blockquote>
<p>随即图和WS小世界模型的一个共同特征就是网络的连接度分布可近似用Poisson分布来表示，该分布在度平均值 <span class="math inline">\(\left\langle k\right\rangle\)</span> 处有一峰值，然后呈指数快速衰减。这意味着当 <span class="math inline">\(k\geq\left\langle k\right\rangle\)</span> 时，度为 <span class="math inline">\(k\)</span> 的节点几乎不存在。因此，这类网络也称为均匀网络或指数网络 (exponential network)。</p>
</blockquote>
<h2 id="scale-free-network">1.4 Scale-Free Network</h2>
<p>该网络的连接度分布函数具有幂律形式，现称为BA模型 [5]。该模型具有以下特征：</p>
<ul>
<li>增长 (growth) 特性：即网络的规模是不断扩大的。<br>
&gt; WWW上每天都有大量新的网页产生</li>
<li>优先连接 (preferential attachment) 特性：即新的节点更倾向于与那些具有较高连接度的“大”节点相连接。这种现象也称为“富者更富 (rich get richer)”或“马太效应 (Matthew effect)”。 &gt; 新发表的文章更倾向于引用一些已被广泛引用的重要文献。</li>
</ul>
<hr>
<h1 id="properties">2 Properties</h1>
<h2 id="small-world-effect">2.1 Small-World Effect</h2>
<blockquote>
<p>Most pairs of vertices in most networks seem to be connected by a short path through the network.</p>
</blockquote>
<p>The small-world effect has obvious implications for the dynamics of processes taking place on networks:</p>
<ul>
<li>If one considers the spread of information, or indeed anything else, across a network, the small-world effect implies that that spread will be fast on most real-world networks.</li>
<li>If it takes only six steps for a rumor to spread from any person to any other, for instance, then the rumor will spread much faster than if it takes a hundred steps, or a million.</li>
<li>This affects the number of “hops” a packet must make to get from one computer to another on the Internet.</li>
<li>The number of legs of a journey for an air or train traveler.</li>
<li>The time it takes for a disease to spread throughout a population.</li>
</ul>
<p><strong>Networks are said to show the small-world effect if the value of <span class="math inline">\(\ell\)</span> scales logarithmically or slower with network size for fixed mean degree.</strong></p>
<h2 id="transitivity横截性-or-clustering-6">2.2 Transitivity(横截性) or Clustering [6]</h2>
<p>The friend of your friend is likely also to be your friend. In terms of network topology, transitivity means the presence of a heightened number of triangles in the network—sets of three vertices each of which is connected to each of the others.</p>
<p>It can be quantified by defining a <strong>clustering coefficient</strong> <span class="math inline">\(C\)</span>, which can be written in three forms:</p>
<ol style="list-style-type: decimal">
<li><p>In this case, <span class="math inline">\(C\)</span> measures the fraction of triples that have their third edge filled in to complete the triangle: <span class="math display">\[ \begin{align} 
C = \frac{3\times \text{number of triangles in the network}}{\text{number of connected triples of vertices}}
\end{align} \]</span> where a “connected triple” means a single vertex with edges running to an unordered pair of others</p></li>
<li><p>In this case, <span class="math inline">\(C\)</span> is the mean probability that two vertices that are network neighbors of the same other vertex will themselves be neighbors, and also mean <strong>probability that the friend of your friend is also your friend</strong>. <span class="math display">\[ \begin{align} 
C = \frac{6\times \text{number of triangles in the network}}{\text{number of paths of length two}}
\end{align} \]</span> where a path of length two refers to a directed path starting from a specified vertex.</p></li>
<li><p>In this case, it tends to <strong>weight</strong> the contributions of <strong>low-degree vertices</strong> more heavily, because such vertices have a small denominator in (3) and hence can give quite different results from (1).[4] <span class="math display">\[ \begin{align} 
C = \frac{1}{n}\sum_i C_i,\quad C_i = \frac{\text{number of triangles connected to vertex $i$}}{\text{number of triples centered on vertex $i$s}}
\end{align} \]</span></p></li>
</ol>
<h2 id="degree-distributions">2.3 Degree Distributions</h2>
<p>The way of presenting degree data is to make a plot of the cumulative distribution function(累积度分布) <span class="math display">\[ \begin{align}
P_k=\sum_{k&#39;=k}^\infty p_{k&#39;}
\end{align} \]</span> which is the probability that the degree is greater than or equal to <span class="math inline">\(k\)</span>. &gt; Such a plot has the advantage that all the original data are representd and also reduces the noise in the tail.</p>
<p>A network appears to have power-law degree destributions if its cumulative degree distribution indicated by their approximately straight-line forms on the doubly logarithmic scales.</p>
<h2 id="community-structure">2.4 <a href="#cs">Community</a> Structure</h2>
<p>The distribution of edges is not only globally, but also <strong>locally inhomogeneous</strong>, with high <strong>concentrations</strong> of edges within special groups of vertices, and low concentrations between these groups. This feature of real networks is called <strong>community structure</strong>, or <strong>clustering</strong>. &gt; <strong>Clustering和Community Detection区别</strong> [19]<br>
&gt; 聚类问题和网络社区划分问题虽然存在内在的一致性，但是在本质上二者并不完全等同。聚类分析问题中的每一个数据点是孤立存在的，只存在与其它数据点的距离信息或者相似度信息；而网络中的每一个节点具备聚类分析问题所不具备的网络拓扑结构性质。网络中的每一个节点不仅受到其邻居的影响，而且还要受到其它节点经过拓扑性质传递给它的影响，这也正是基于网络拓扑结构性质相似度构造方法优于基于节点局部信息相似度构造方法的原因所在。</p>
<h2 id="network-resilience">2.5 Network <a href="#Resilience">Resilience</a></h2>
<p>There are a variety of different ways in which vertices can be removed. For example, one could remove vertices at random from a network, or one could target some specific class of vertices, such as those with the highest degrees.</p>
<p>The work[11] study the effect of vertex deletion:</p>
<ul>
<li><a href="#mgd">Mean Geodesic Distance</a> is almost entirely unaffected by ramdom vertex removal since most of the vertices have low degree.</li>
<li>Mean Geodesic Distance increases very sharply with the fraction of the highest degree vertices removed.</li>
</ul>
<p>Resilience can be related to the graph diameter: a graph whose diameter does not increase much on node or edge removal has higher resilience. [Palmer et al. 2002; Albert et al. 2000].</p>
<h2 id="largest-component">2.6 Largest <a href="#component">Component</a></h2>
<p>In some networks the size of the largest component is an important quantity. &gt; In a communication network like the Internet the size of the largest component represents the largest fraction of the network within which communication is possible and hence is a measure of the effectiveness of the network at doing its job.</p>
<h2 id="network-centrality-15">2.7 Network Centrality [15]</h2>
<h3 id="betweenness-centrality-16">2.7.1 <a href="#bc">Betweenness Centrality</a> [16]</h3>
<p>Betweenness centrality can be viewed as a measure of network resilience - it tells us how many geodesic paths will get longer when a vertex is removed from the network. 顶点 <span class="math inline">\(i\)</span>的介数定义为 <span class="math display">\[ \begin{align}
BC_i=\sum_{s\neq i\neq t}\frac{n_{st}^i}{g_{st}}
\end{align} \]</span> 其中，<span class="math inline">\(g_{st}\)</span>为从顶点<span class="math inline">\(s\)</span>到顶点<span class="math inline">\(t\)</span>的最短路径的书面，<span class="math inline">\(n_{st}^i\)</span>是从顶点<span class="math inline">\(s\)</span>到顶点<span class="math inline">\(t\)</span>的<span class="math inline">\(g_{st}\)</span>条最短路径中经过顶点<span class="math inline">\(i\)</span>的最短路径的数目。</p>
<p>Latora and Marchiori [12] [13] have considered the <em>harmonic mean distance</em> between a vertex and all others can be viewed as a measure of network resilience, indicating how much effect on path length the removal of a vertex will have.</p>
<h3 id="closeness-centrality-17">2.7.2 <a href="#cc">Closeness Centrality</a> [17]</h3>
<p>The <a href="#mgd">mean geodesic distance</a> for vertex <span class="math inline">\(i\)</span> is: <span class="math display">\[ \begin{align}
\ell_i = \frac{1}{n}\sum_j d_{i,j}
\end{align} \]</span> This quantity takes low values for vertices that are separated from others by only a short geodesic distance on average.</p>
<p>However, the mean geodesic distance <span class="math inline">\(\ell_i\)</span> gives low values to more central nodes and high values to less central ones. Therefore, researchers commonly calculate its inverse, called <strong>closeness centrality</strong>: <span class="math display">\[ \begin{align}
C_i=\frac{1}{\ell_i}=\frac{n}{\sum_j d_{i,j}}
\end{align} \]</span></p>
<blockquote>
<p>Network Centrality 还有很多其他形式的定义，例如：Eigenvector centrality, Katz centrality, PageRank centrality, Cross-clique centrality, Percolation centrality, etc [18].</p>
</blockquote>
<h2 id="network-navigation">2.8 Network Navigation</h2>
<p>Stanley Milgram’s famous small-world experiment’s [10] results demonstrate that there exist short paths in the network, but they also demonstrate that ordinary people are good at finding them.</p>
<p>If it were possible to construct artificial networks that were easy to navigate in the same way that social networks appear to be, it has been suggested they could be used to build efficient database structures or better peer-to-peer computer networks</p>
<hr>
<h1 id="application">3 Application</h1>
<h2 id="anomaly-detection-20">3.1 Anomaly Detection [20]</h2>
<ul>
<li><p><strong>Definition</strong><br>
<em>Anomalies</em> are patterns in data that do not conform to a well defined notion of normal behavior.</p></li>
<li><strong>Research Areas</strong>
<ul>
<li><em>Statistics</em></li>
<li><em>Machine learning</em></li>
<li><em>Data mining</em></li>
<li><em>Information theory</em></li>
<li><em>Spectral theory</em></li>
</ul></li>
<li><strong>Practical Applications</strong>
<ul>
<li><em>Intrusion Detection</em></li>
<li><em>Fraud Detection</em></li>
<li><em>Medical and Public Health Anomaly Detection</em></li>
<li><em>Industrial Damage Detection</em></li>
<li><em>Image Processing</em></li>
<li><em>Anomaly Detection in Text Data</em></li>
<li><em>Sensor Networks</em></li>
</ul></li>
</ul>
<h2 id="link-analysis-21-22">3.2 Link Analysis [21] [22]</h2>
<p>Social interaction on the Web involves both positive and negative relationships — people form links to indicate friendship, support, or approval; but they also link to signify disapproval of others, or to express disagreement or distrust of the opinions of others.</p>
<p>Link Analysis provide insight into some of the fundamental principles that drive the formation of signed links in networks, shedding light on theories of balance and status from social psychology; they also suggest social computing applications by which the attitude of one user toward another can be estimated from evidence provided by their relationships with other members of the surrounding social network.</p>
<h2 id="recommender-systems-23">3.3 Recommender Systems [23]</h2>
<ul>
<li><strong>Social Network</strong> [24] [25] [27] [28] [29]</li>
<li><strong>Graphical Model</strong> [26]</li>
</ul>
<h2 id="deep-learning-for-graph-30-31">3.4 Deep Learning for Graph [30] [31]</h2>
<h2 id="node-representation-and-classification">3.5 Node Representation and Classification</h2>
<ul>
<li><p><strong>Node Classification</strong><br>
When dealing with large graphs, such as those that arise in the context of online social networks, a subset of nodes may be labeled. These labels can indicate demographic values, interest, beliefs or other characteristics of the nodes (users). A core problem is to use this information to extend the labeling so that all nodes are assigned a label (or labels). [32] [33] [34]</p></li>
<li><p><strong>Node Representation</strong><br>
Each vertex of the graph is represented with a low-dimensional vector in which meaningful semantic, relational and structural information conveyed by the graph can be accurately captured. [35] [36]</p></li>
</ul>
<h2 id="community-detection-37">3.6 Community Detection [37]</h2>
<h3 id="样例---社交网络算法在金融欺诈中的应用">3.6.0 样例 - 社交网络算法在金融欺诈中的应用</h3>
<ul>
<li>社交网络算法
<ul>
<li>分析指标：degree, <a href="#cc">closeness centrality</a>, <a href="#bc">betweenness centrality</a>, <a href="#clco">clustering coefficient</a>，等等。</li>
<li>算法：
<ul>
<li>PageRank</li>
<li>社区发现</li>
</ul></li>
</ul></li>
<li>在工业界的其他应用包括：精准营销，改善搜索/帮助推荐，网络系统安全</li>
</ul>
<p>ppt下载链接 <a href="http://pan.baidu.com/s/1pLay8UR" class="uri" target="_blank" rel="external">http://pan.baidu.com/s/1pLay8UR</a>{:target=“_blank“}</p>
<h3 id="研究现状">3.6.1 研究现状</h3>
<p>目前流行的网络聚类方法是社区发现，已有的社区发现方法主要用来发现类内链接紧密、类间链接稀疏的网络结构(以下称该类结构为“<strong>传统社区</strong>”)。社区结构对深入理解网络拓扑结构、挖掘网络潜在模式、预测网络行为都具有十分重要的意义。而实际网络的结构比较复杂，人们预先并不知道网络中存在什么结构。</p>
<p>传统社区用于发现网络中<strong>紧密链接的聚类结构</strong>，根据节点链接紧密特性定义聚类中节点的相似性。当网络中不存在社区结构或存在其它结构时，传统社区发现方法不能有效识别网络的真实结构。</p>
<p>近来研究者提出采用一些<strong>概率生成模型</strong>，可发现网络中传统社区及之外的更多类型的聚类结构，该类聚类方法假设同类节点与它类具有相同的链接概率。基于该假设可刻画多种类型网络结构，如</p>
<ul>
<li><em>同类节点链接紧密、与异类节点链接稀疏的结构</em>(传统社区)；</li>
<li><em>与同类节点链接稀疏、与异类节点链接紧密的结构</em>(二分图或多分图)；</li>
<li><em>星型链接模式结构</em>。</li>
</ul>
<p>因此，该类方法可发现比传统社区更广义的聚类结构，以下统称为“<strong>广义社区</strong>”结构，发现这种结构的方法为广义社区发现方法。</p>
<p>传统社区发现的问题[2,3]：</p>
<ul>
<li>传统社区发现识别的聚类结构不准确。许多流行的传统社区发现方法基于模块度函数求解社区结构，存在分辨率和尺度问题，如社区发现结果易淹没小的社区。因此，该类方法的聚类结果不能反映实际网络的聚类事实。</li>
<li>传统社区发现在网络潜在结构不存在紧密链接子图结构时可能失效，也不能发现网络潜在的其它类型结构。在线社交平台的网络结构规律复杂，我们很难获取关于网络的先验知识，不知道网络是传统社区结构、二分图结构或其它多种类型结构的混合。大多传统社区发现方法假设网络中存在链接紧密的子图结构，且只能发现此类结构。</li>
<li>传统社区发现不能在发现网络社区结构的同时，识别出类间的交互规律：传统社区发现方法的目的是将网络节点按照链接紧密性聚类，不能提供社区间链接模式，不易于网络结构可视化及直观了解网络交互规律。</li>
</ul>
<hr>
<h3 id="复杂网络上的社区发现">3.6.2 复杂网络上的社区发现</h3>
<div class="figure">
<img src="https://ooo.0o0.ooo/2017/02/25/58b14aea858ce.png" alt="复杂网络上的社区发现.png">
<p class="caption">复杂网络上的社区发现.png</p>
</div>
<h4 id="传统算法-traditional-methods">3.6.2.1 传统算法 (Traditional methods)</h4>
<h5 id="图分割-graph-partitioning">3.6.2.1.1 图分割 (Graph partitioning)</h5>
<p>社区可以看做密集子图结构，使用图分割算法来解决。图分割问题的目标是把图中的节点分成gg个预定大小的群组，这些群组之间的边数目最小，这个问题是NP-hard 的。</p>
<ul>
<li><strong>K-L算法（Kernighan-Lin algorithm）</strong>通过基于贪婪优化的启发式过程把网络分解为2个规模已知的社区。该算法为网络的划分引入一个增益函数，定义为两个社区内部的边数与两个社区边数之间的差，寻求Q的最大划分办法。[38]</li>
</ul>
<blockquote>
<p>K-L算法必须预先指定2个社区的大小，否则会得到错误的结果。这使得K-L算法无法应用于大多数真实网络。即使K-L算法的这一缺点得以克服，作为图分割方法，其先天性不足仍然难以解决。K-L算法在稀疏图中的时间复杂度是<span class="math inline">\(O(n^3)\)</span>。</p>
</blockquote>
<ul>
<li><strong>谱二分法（spectral bisection method）</strong>早期的分割都是二分图，社区发现也是基于二分的，遇到多分的情况就把其中一个子图再分割。比较经典的有谱二分法，利用拉普拉斯矩阵的第二小特征值<span class="math inline">\(\lambda_2\)</span>对社区二分类，这其实是属于谱方法的一种特例。[39] 谱二分法的步骤如下：
<ul>
<li>对于网络的相似度矩阵<span class="math inline">\(W=[w_{i,j}]\)</span>，计算对角矩阵 <span class="math inline">\(D_{i,i}=\sum\limits_j^Nw_{i,j}\)</span>，其中<span class="math inline">\(w_{i,j}\)</span></li>
<li>计算拉普拉斯（Laplacian）矩阵 <span class="math inline">\(L=D-W\)</span></li>
</ul></li>
</ul>
<blockquote>
<p>该拉普拉斯矩阵必有一个特征值为0，且对应的特征向量为<span class="math inline">\(\vec{1}=[1,1,\cdots,1]^{\rm T}\)</span>。而不为零的特征值所对应的特征向量的各元素中，同一个社区内的节点对应的元素是近似相等的。可以征明，除零特征值外，其它特 征值均大于零。谱二分法即是根据<span class="math inline">\(L\)</span>的第二个小特征值<span class="math inline">\(\lambda_2\)</span>：将网络分为两个社区。<span class="math inline">\(\lambda_2\)</span>被称为图的代数连接度，如果其值越小，谱二分法的效果就越好。谱二分法的主要缺点是只能将图分成2个子图，或者说偶数个子图。这使得人们在使用这种方法时，预先不能确定究竟将图分成多少个子图才合适。</p>
</blockquote>
<ul>
<li><strong>最大流（maximum flows）</strong>基于最大流的算法是G.W.Flake提出的。他给网络加了虚拟源节点ss和终点节点tt，并证明了经过最大流算法之后，包含源点ss的社区恰好满足社区内节点链接比与社区外的链接要多的性质。[40] [41]</li>
<li><strong>多层次图分割（level-structure partitioning）</strong>[42]</li>
</ul>
<h5 id="聚类-clustering">3.6.2.1.2 聚类 (Clustering)</h5>
<p>当社区的边非常密集，数目远大于点时，图分割可能就不太好使了，这时候社区发现可能更接近于聚类。我们把社区发现看做一组内容相似的物体集合，使用聚类算法。和图中的社区发现相比，图中的社区点与点之间可以用边来表示联系的紧密，而聚类中的社区，需要定义点之间的相似度，比如说根据邻接关系定义：<span class="math display">\[d_{ij}=\sqrt{\sum_{k\neq i,j}(a_{ik}-a_{jk})^2}\]</span>其中<span class="math inline">\(\mathbf{A}=(a_{ij})\)</span>为邻接矩阵，<span class="math inline">\(i\)</span>和<span class="math inline">\(j\)</span>的邻居越多，节点相似度越高。 聚类算法和网络发现（聚类相关的）算法可以很容易地互相转化。另外，社区发现可以是局部的，而聚类是全网络的。</p>
<ul>
<li><strong>层次聚类（hierarchical clustering）</strong>层次聚类假设社区是存在层次结构的（其实不一定额，可能是中心结构），计算网络中每一对节点的相似度。 然后分为凝聚法和分裂法两种：[43]
<ul>
<li><em>凝聚法（Agglomerative algorithms）</em>：根据相似度从强到弱连接相应节点对，形成树状图（Dendrogram），根据需求对树状图进行横切，获得社区结构。凝聚法的<strong>缺陷</strong>在于在某些应用中，当社区数目已经知道时，未必能得到正确的社区结构。另外，凝聚算法倾向于发现社区的核心，而忽略社区的外围。社区的核心部分往往与它周围点联系密切，因而易于发现．两社区的蒯边部分由于相对来说联系较少，所以很难划分。在一些情况下，某个点仅仅和特定的社区有一条边，凝聚算法很难正确划分该点。</li>
<li><em>分裂法（Divisive algorithms）</em>：找出相互关联最弱的节点，并删除他们之间的边，通过这样的反复操作将网络划分为越来越小的组件，连通的网络构成社区。</li>
</ul></li>
<li><strong>划分聚类（Partitional clustering）</strong>像k-means就很好，可以使用上面的相似度来聚类 。[44]</li>
<li><strong>谱聚类（Spectral clustering）</strong>图分割中的如 Ratio Cut和Normalized Cut其实和谱聚类是等价的（见参考3），所以谱聚类也能用在社区发现上。</li>
<li><strong>局部聚类</strong></li>
</ul>
<h4 id="分裂方法divisive-algorithms">3.6.2.2 分裂方法（Divisive algorithms）</h4>
<p>这里的分裂法和层次聚类中的类似，区别是前者不计算节点相似度，而是删除是两个社区之间的关联边，这些边上的两点的相似度不一定很低。其中最著名的算法就是<strong>Girvan-Newman算法</strong>，根据以下假设：社区之间所存在的少数几个连接应该是社区间通信的瓶颈，是社区间通信时通信流量的必经之路。如果我们考虑网络中某种形式的通信并且寻找到具有最高通信流量（比如最小路径条数）的边，该边就应该是连接不同社区的通道。Girvan-Newman算法就是这样，迭代删除<strong>边介数（Edge Betweenness）</strong>最大的边。[45]</p>
<h4 id="基于模块度的方法modularity-based-methods">3.6.2.3 基于模块度的方法（Modularity-based methods）</h4>
<blockquote>
<p>Newman在自己2006年的文章里也证明了Modularity其实是对模块度矩阵进行一个谱分析。这也体现了Modularity方法的普适性和良好的可解释性。</p>
</blockquote>
<p>模块度不仅仅作为优化的目标函数提出，它也是目前是最流行的用来衡量社区结果好坏的标准之一（它的提出被称作社区发现研究历史上的里程碑)。我们知道，社区是节点有意识地紧密联系所造成的，它内部边的紧密程度总比一个随机的网络图来的紧密一些，模块度的定义就是基于此，它表示所有被划分到同一个社区的边所占的比例，再减除掉完全随机情况时被划分到同一个社区的边所占的比例： <span class="math display">\[ \begin{align}
Q=\frac{1}{2M}\sum_{ij}(a_{i,j}-\frac{k_ik_j}{2M})\delta(C_i,C_j)=\frac{1}{2M}\sum_{ij}b_{ij}\delta(C_i,C_j)
\end{align} \]</span> 其中<span class="math inline">\(\mathbf{A}=(a_{ij})\)</span>是网络的邻接矩阵，<span class="math inline">\(M\)</span>是整个图中边的数目，<span class="math inline">\(k_i\)</span> 是顶点<span class="math inline">\(i\)</span>的度数，<span class="math inline">\(C_i\)</span>表示节点<span class="math inline">\(i\)</span>所属的社区，如果两个节点属于同一个社区，则<span class="math inline">\(\delta\)</span>取值1，否则为0。注意公式（1） 的意义，<span class="math inline">\(\frac{a_{ij}}{2M}\)</span>是两个顶点之间连接的概率，如果我们保持一个网络的度分布但对其连边进行随机洗牌，任意一对节点在洗牌后存在连接的概率为<span class="math inline">\(\frac{k_ik_j}{2M}\)</span>。上式中括号表达的就是节点之间的实际连边概率高于期待值的程度。另<span class="math inline">\(\mathbf{B}=(b_{ij})_{N\times N}\)</span>也称为<strong>模块度矩阵</strong>（Modularity matrix）。</p>
<blockquote>
<p>modularity在large-scale network中有一个缺陷：resolution limit。在large network中，基于modularity的方法找不到那些small community，即便这些small community的结构都很明显。[58]</p>
</blockquote>
<p>公式还可以写成另一种形式： <span class="math display">\[ \begin{align}
Q=\sum_{i=1}^{n_c}(e_{ii}-a_i^2)
\end{align} \]</span> 其中 <span class="math inline">\(e_{ij}=\sum\limits_{vw}\frac{a_{vw}}{2M}\delta(C_i, C_j)\)</span>，且 <span class="math inline">\(e_{ii}\)</span> 是每个社团内区<span class="math inline">\(i\)</span>内部顶点之间的连边数占整个网络边数的比例，<span class="math inline">\(a_i=\frac{k_i}{2M}=\sum_je_{ij}\)</span>意味着一端与社团 <span class="math inline">\(i\)</span> 中顶点相连的连边的比例，<span class="math inline">\(n_c\)</span> 是整个网络中社区的数量。</p>
<p>在实际计算里，上式要求对社区及其内部节点进行遍历，这个计算复杂度是很大的。Newman(2006) [54]对上式进行了化简，得到矩阵表达如下： <span class="math display">\[ \begin{align}
Q=\frac{1}{2M}\sum_{ij}\sum_r\left[a_{ij}-\frac{k_ik_j}{2m}\right]S_{ir}S_{jr}=\frac{1}{2M}{\rm Tr}(\mathbf{S}^{\rm T}\mathbf{B}\mathbf{S})
\end{align} \]</span> 其中<span class="math inline">\(S\)</span>是<span class="math inline">\(N\times n_c\)</span>的矩阵，且如果顶点<span class="math inline">\(i\)</span>属于社区<span class="math inline">\(r\)</span>则<span class="math inline">\(S_{ir}\)</span>是1，否则为0.</p>
<p>模块度的一个优点是好坏与社区中点的数目无关。模块度真是个好东西，第一次对社区这个模糊的概念提出了量化的衡量标准（不过据说对于小粒度的不太准）。所以对模块度的算法优化多种多样，从贪心到模拟退火等应有尽有。</p>
<ul>
<li><strong>贪心策略（Greedy techniques）</strong> 有两个比较经典的算法，分别是
<ul>
<li>Fast greedy算法（CNN算法）[51]</li>
<li>Multilevel算法（Fast-Unfolding算法）[52] 该算法优点如下：（1）计算速度很快，可用于大规模网络。（2）是一种自下而上的凝聚过程，不会出现对小规模社团的探测遗漏现象，即解决了分辨率问题。（3）可应用于大规模的加权网络。 然而，在实际情况下，在顶点的直接邻近内的封闭社区可能是不准确的并且产生虚假伪分区。 因此，不清楚某些中间分区是否可以对应于图的有意义的分层级别。 此外，算法的结果取决于在顶点上的顺序扫描的顺序。 &gt; Fast-Unfolding算法可以Spark中实现，已有现成的代码。[53]</li>
</ul></li>
<li><strong>模拟退火（Simulated annealing）</strong></li>
<li><strong>极值优化（Extremal optimization）</strong></li>
<li><strong>谱优化（Spectral optimization）</strong></li>
</ul>
<h4 id="谱方法spectral-algorithms">3.6.2.4 谱方法（Spectral Algorithms）</h4>
<p>基于谱分析的社区算法基于如下事实，在同一个社区内的节点，它在拉普拉斯矩阵中的特征向量近似。将节点对应的矩阵特征向量（与特征值和特征向量有关的都叫谱）看成空间坐标，将网络节点映射到多维向量空间去，然后就可以运用传统的聚类算法将它们聚集成社团。这种方法不可避免的要计算矩阵的特征值，开销很大，但是因为能直接使用很多传统的向量聚类的成果，灵活性很高。</p>
<h4 id="动态算法dynamic-algorithms">3.6.2.5 动态算法（Dynamic Algorithms）</h4>
<p>自旋模型和同步算法应该是物理学家提出来的算法，话说物理学家在社区发现领域十分活跃，发了不少论文。随机游走是基于以下思想：如果存在很强的社区结构，那么随机游走器（random walker)会在社区内部停留更长的时间，因为社区内部的边密度比较高。</p>
<ul>
<li><strong>自旋模型（Spin models）</strong></li>
<li><strong>随机游走（Random walk）</strong></li>
<li><strong>同步算法（Synchronization）</strong></li>
</ul>
<h4 id="基于统计推断的算法methods-based-on-statistical-inference">3.6.2.6 基于统计推断的算法（Methods based on statistical inference）</h4>
<p>基于统计推断的方法包括观察到的数据集和对模型的假设。如果数据集是图，模型假设对节点之间如何联系的描述就要符合真实的图结构。[47] [48]</p>
<ul>
<li><strong>生成模型（Generative models）</strong></li>
<li><strong>判别模型（Blockmodeling, model selection and information theory）</strong> &gt; 赫赫有名的<strong>infomap</strong>这个方法是从编码的角度给了社区一个良好的解释，发现了网络的一种最优的二级编码就发现了对应的社区结构。思想是相当绝妙的，效果也很好。[49] [50]</li>
</ul>
<h4 id="总结">3.6.2.7 总结</h4>
<p>记<span class="math inline">\(n_1=\mid V\mid\)</span>，<span class="math inline">\(n_2=\mid E\mid\)</span></p>
<table>
<thead>
<tr class="header">
<th>算法</th>
<th>优化目标</th>
<th>计算复杂度</th>
<th>适用情况</th>
<th>局限</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Q modularity</td>
<td>最大化Q-modularity</td>
<td><span class="math inline">\(n_1^2\)</span></td>
<td>无向无权多分量</td>
<td>不适合大网络</td>
</tr>
<tr class="even">
<td>Edge-Betweenness</td>
<td>最小化社区间连边的betweenness</td>
<td><span class="math inline">\(O(n_1n_2^2)\)</span></td>
<td>有向有权多分量</td>
<td>慢</td>
</tr>
<tr class="odd">
<td>Leading Eigenvector</td>
<td>对拉普拉斯矩阵第二小特征根对应特征向量的聚类</td>
<td><span class="math inline">\(O(n_1^2)\)</span></td>
<td>无向无权多分量</td>
<td></td>
</tr>
<tr class="even">
<td>Fast Greedy</td>
<td>使用社区合并算法来快速搜索最大Q-modularity</td>
<td><span class="math inline">\(O(n_2\log^2 n_1)\)</span></td>
<td>无向有权多分量</td>
<td>不适合小网络</td>
</tr>
<tr class="odd">
<td>Multi Level</td>
<td>使用社区展开算法来快速搜索最大Q-modularity</td>
<td><span class="math inline">\(O(n_1\log n_1)\)</span></td>
<td>无向有权多分量</td>
<td>不适合小网络</td>
</tr>
<tr class="even">
<td>Walk Trap</td>
<td>最大化社区间的流距离</td>
<td><span class="math inline">\(O(n_1^2\log n_1)\)</span></td>
<td>无向有权多分量</td>
<td></td>
</tr>
<tr class="odd">
<td>Label Propagation</td>
<td>每个节点取邻居中最流行的标签，迭代式收敛</td>
<td><span class="math inline">\(O(n_2)\)</span></td>
<td>无向有权多分量</td>
<td>结果不稳定</td>
</tr>
<tr class="even">
<td>Info map</td>
<td>最小化随机流的编码长度</td>
<td><span class="math inline">\(O(n_2)\)</span></td>
<td>有向有权单分量</td>
<td></td>
</tr>
<tr class="odd">
<td>Role-based community</td>
<td>划分出在流中地位类似的节点</td>
<td><span class="math inline">\(n_1^3\)</span></td>
<td>有向有权单分量</td>
<td>结果不稳定</td>
</tr>
</tbody>
</table>
<hr>
<h3 id="社区发现算法特征">3.6.3 社区发现算法特征</h3>
<h4 id="优化目标">3.6.3.1 优化目标</h4>
<p>有一些社区发现算法比如谱方法，K-L算法，以及基于最大流的社区发现方法等，给出明确的的目标函数，并提出算法来最优化目标函数。 常用的优化目标函数有：</p>
<h5 id="normailized-cutratio-cut和conductance">3.6.3.1.1 Normailized Cut、Ratio Cut和conductance</h5>
<p>记<span class="math inline">\(\pi=(C_1,C_2,\cdots,C_K)\)</span>表示网络的社区，同时满足<span class="math inline">\(C_i\bigcap C_j=\emptyset,\, \bigcup_{i=1}^KC_i=V\)</span>，<strong>规范化割集标准（Normailized Cut</strong>）和<strong>比例割集标准（Ratio Cut）</strong>定义为： <span class="math display">\[ \begin{align}
Ratio\, Cut(\pi)=\frac{1}{K}\sum_{i=1}^K\frac{cut(C_i,\overline{C_i})}{|C_i|}
\end{align} \]</span> <span class="math display">\[ \begin{align}
Normailized\, Cut(\pi)=\frac{1}{K}\sum_{i=1}^K\frac{cut(C_i,\overline{C_i})}{vol(C_i)}, vol(C_i)=\sum_{v\in C_i}k_v
\end{align} \]</span></p>
<p>其中 <span class="math inline">\(cut(C_i,\overline{C_i})\)</span> 表示两者之间的联系数目。两个目标函数的目标是使得社区之间的边数量最小化的同时，避免出现类似于只包含1个成员的小社区。</p>
<p>连通度(conductance)也是类似的定义:[59] <span class="math display">\[ \begin{align}
Conductance(C_i)=\frac{cut(C_i,\overline{C_i})}{\min\{vol(C_i),vol(\overline{C_i})\}}
\end{align} \]</span></p>
<h5 id="kernighan-lin-object">3.6.3.1.2 Kernighan-Lin object</h5>
<p>K-L目标函数旨在使两个相同大小的社区之间的边联系最小： <span class="math display">\[ \begin{align}
KL_{obj}(C_1,\ldots,C_k)=\sum_{i\neq j}A(C_i,C_j)
\end{align} \]</span> 其中<span class="math inline">\(A(C_i,C_j)=\sum_{u\in C_i,v\in C_j}A(u,v), |C_1|=|C_2|=\ldots=|C_k|\)</span></p>
<h5 id="modularity">3.6.3.1.3 Modularity</h5>
<p>模块度已在3.6.2.3节提过。</p>
<h4 id="粒度控制社区数目可不可控">3.6.3.2 粒度控制（社区数目可不可控）</h4>
<p>对于有层次的社区发现算法来说的，比如某些二分社区算法，是通过不断递归的划分子社区来获得预定的社区数目。而某些算法，像层次聚类和MCL（Markov clustering），基于概率模型的社区发现算法等，允许用户通过调节参数来间接控制输出社区的数目。</p>
<p>另一些算法，像模块度优化算法，它的社区数目是由优化函数决定的，不需要用户来设定社区的数目。</p>
<h4 id="规模">3.6.3.3 规模</h4>
<p>很多算法在设计的时候，并没有特别地考虑伸缩性，在面对整个Web以及大型社交网络时动辄百万甚至千万个点时效果不佳。比如G-N算法，需要计算即通过每条边的最短路径数目（edge betweeness)，复杂度相当高，像谱聚类算法，能处理10K个点和70M条边就不错了。</p>
<p>所以，有些算法比如Shingling算法等，使用的方法相对简单，从而能适合大规模的社区发现的运行要求。</p>
<h4 id="重叠社区">3.6.3.4 重叠社区</h4>
<p>很多社区发现算法，比如图分割算法，将整个网络划分为多个独立的社区结构。但是在现实中，许多网络并不存在绝对的彼此独立的社团结构，相反，它们是由许多彼此重叠互相关联的社团构成，比如说在社交网络中，一个人根据兴趣的不同，有可能属于多个不同的小组等。所以，很多类似派系过滤算法（CPM - Clique Percolation Method）[55]这样旨在发现重叠社区的算法也被不断地提出来。</p>
<h4 id="评价标准">3.6.3.5 评价标准</h4>
<h5 id="准确率召回率f1值">3.6.3.5.1 准确率，召回率，F1值</h5>
<p>一个大规模数据集合中检索文档的时，可把文档分成四组：系统检索到的相关文档（A），系统检索到的不相关文档（B），相关但是系统没有检索到的文档（C），不相关且没有被系统检索到的文档（D）： 准确度定义为： <span class="math display">\[ \begin{align}
pr=\frac{A}{A+C}
\end{align} \]</span></p>
<p>召回率定义为： <span class="math display">\[ \begin{align}
rc=\frac{A}{A+B}
\end{align} \]</span></p>
<p>F-measure是准确率和召回率协调之后的结果，定义为： <span class="math display">\[ \begin{align}
PWF=\frac{2\times pr \times rc}{pr+rc}
\end{align} \]</span></p>
<p>同理，社区也可以用这个概念。</p>
<h5 id="平均聚类纯度average-cluster-purity">3.6.3.5.2 平均聚类纯度（average cluster purity）</h5>
<p>假设算法发现了<span class="math inline">\(C=\{C_1,\ldots,C_K\}\)</span>个社区，我们假设社区<span class="math inline">\(C_i\)</span>有<span class="math inline">\(n_i\)</span>个点，，每个点分别为<span class="math inline">\(\{v_{1,i},\ldots,v_{n_i,i}\}\)</span>。令<span class="math inline">\(M_{l,i}\)</span>为<span class="math inline">\(v_{l,i}\)</span>真实归属的社区的标签，平均聚类纯度为定义为： <span class="math display">\[ \begin{align}
ACP=\frac{1}{k}\sum_{i=1}^k\sum_{l=1}^{n_i}\frac{\delta(dom_i\in M_{l,i})}{n_i}
\end{align} \]</span> 即社区<span class="math inline">\(C_i\)</span>中主要标签的点占社区所有点的数目比例。</p>
<h5 id="互信息">3.6.3.5.3 互信息</h5>
<p>首先来回顾熵的定义,在一个分布内包含的信息为熵： <span class="math display">\[ \begin{align}
H(X)=-\sum_{x \in X}p(x)\log p(x)
\end{align} \]</span></p>
<p><strong>互信息（mutual information)</strong>描述了两个分布之间的相关性： <span class="math display">\[ \begin{align}
I(X;Y)=H(X)-H(X|Y)=\sum_{y \in Y}\sum_{x \in X}p(x,y)\log(\frac{p(x,y)}{p(x)p(y)})
\end{align} \]</span> 但事实上，对于一个划分<span class="math inline">\(X\)</span>，任何一个从<span class="math inline">\(X\)</span>派生的划分<span class="math inline">\(Y\)</span>都和<span class="math inline">\(X\)</span>有相同的互信息，尽管这些划分都不尽相同。在这种情况下条件熵<span class="math inline">\(H(X|Y)\)</span>都近乎为0，这也导致了互信息<span class="math inline">\(I(X;Y)\)</span>几乎等于<span class="math inline">\(H(X)\)</span>。为了避免这种情况，Danon et al.提出了归一化互信息（normalized mutual information），直到现在都使用得非常广泛：[57] [60] <span class="math display">\[ \begin{align}
I_{norm}(\mathcal{X},\mathcal{Y})=\frac{2I(X;Y)}{H(X)+H(Y)}
\end{align} \]</span> 所谓两个事件相关性的量化度量，就是在了解其中一个<span class="math inline">\(Y\)</span>的前提下，对消除另一个<span class="math inline">\(X\)</span>不确定性所提供的信息量。 规范化的互信息定义为 <span class="math display">\[ \begin{align}
NMI(X;Y)=\frac{I(X;Y)}{\sqrt{H(X)H(Y)}}
\end{align} \]</span> 我们将划分当做一个结点落在社区的概率分布，然后计算社区划分结果和真实情况的NMI值，具体例子见参考《社会计算:社区发现和社会媒体挖掘》[56].</p>
<p>[1]: <a href="http://vdisk.weibo.com/s/ztDcAsY3JGuzD" target="_blank" rel="external">汪小帆, 李翔, and 陈关荣. 复杂网络理论及其应用. 清华大学出版社有限公司, 2006.</a>{:target=“_blank“}</p>
<p>[2]: <a href="http://link.springer.com/book/10.1007/b106453" target="_blank" rel="external">Brandes, Ulrik, and Thomas Erlebach. Network analysis: methodological foundations. Vol. 3418. Springer Science &amp; Business Media, 2005.</a>{:target=“_blank“}</p>
<p>[3]: <a href="http://link.springer.com/chapter/10.1007/978-1-4612-0619-4_7" target="_blank" rel="external">Bollobás, Béla. “Random graphs.” Modern Graph Theory. Springer New York, 1998. 215-252.</a>{:target=“_blank“}</p>
<p>[4]: <a href="http://www.nature.com/nature/journal/v393/n6684/abs/393440a0.html" target="_blank" rel="external">Watts, Duncan J., and Steven H. Strogatz. “Collective dynamics of ‘small-world’networks.” nature 393.6684 (1998): 440-442.</a>{:target=“_blank“}</p>
<p>[5]: <a href="http://science.sciencemag.org/content/286/5439/509" target="_blank" rel="external">Barabási, Albert-László, and Réka Albert. “Emergence of scaling in random networks.” science 286.5439 (1999): 509-512.</a>{:target=“_blank“}</p>
<p>[6]: <a href="http://epubs.siam.org/doi/abs/10.1137/s003614450342480" target="_blank" rel="external">Newman, Mark EJ. “The structure and function of complex networks.” SIAM review 45.2 (2003): 167-256.</a>{:target=“_blank“}</p>
<p>[7]: <a href="http://dl.acm.org/citation.cfm?id=578533" target="_blank" rel="external">Gary, Michael R., and David S. Johnson. “Computers and Intractability: A Guide to the Theory of NP-completeness.” (1979).</a>{:target=“_blank“}</p>
<p>[8]: <a href="http://repository.cmu.edu/compsci/565/" target="_blank" rel="external">Palmer, Christopher R., et al. “The connectivity and fault-tolerance of the Internet topology.” (2001).</a>{:target=“_blank“}</p>
<p>[9]: <a href="http://ieeexplore.ieee.org/abstract/document/965863/" target="_blank" rel="external">Tauro, Sudhir Leslie, et al. “A simple conceptual model for the internet topology.” Global Telecommunications Conference, 2001. GLOBECOM’01. IEEE. Vol. 3. IEEE, 2001.</a>{:target=“_blank“}</p>
<p>[10]: <a href="http://www.jstor.org/stable/pdf/2786545.pdf" target="_blank" rel="external">Travers, Jeffrey, and Stanley Milgram. “An experimental study of the small world problem.” Sociometry (1969): 425-443.</a>{:target=“_blank“}</p>
<p>[11]: <a href="http://www.nature.com/nature/journal/v406/n6794/abs/406378A0.html" target="_blank" rel="external">Albert, Réka, Hawoong Jeong, and Albert-László Barabási. “Error and attack tolerance of complex networks.” nature 406.6794 (2000): 378-382.</a>{:target=“_blank“}</p>
<p>[12]: <a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.87.198701" target="_blank" rel="external">Latora, Vito, and Massimo Marchiori. “Efficient behavior of small-world networks.” Physical review letters 87.19 (2001): 198701.</a>{:target=“_blank“}</p>
<p>[13]: <a href="http://link.springer.com/article/10.1140%2Fepjb%2Fe2003-00095-5?LI=true" target="_blank" rel="external">Latora, Vito, and Massimo Marchiori. “Economic small-world behavior in weighted networks.” The European Physical Journal B-Condensed Matter and Complex Systems 32.2 (2003): 249-263.</a>{:target=“_blank“}</p>
<p>[14]: <a href="http://dl.acm.org/citation.cfm?id=1132954" target="_blank" rel="external">Chakrabarti, Deepayan, and Christos Faloutsos. “Graph mining: Laws, generators, and algorithms.” ACM computing surveys (CSUR) 38.1 (2006): 2.</a>{:target=“_blank“}</p>
<p>[15]: <a href="http://cs.brynmawr.edu/Courses/cs380/spring2013/section02/slides/05_Centrality.pdf" target="_blank" rel="external">Network Centrality Based on materials by Lada Adamic, UMichigan</a>{:target=“_blank“}</p>
<p>[16]: <a href="http://www.jstor.org/stable/3033543" target="_blank" rel="external">Freeman, Linton C. “A set of measures of centrality based on betweenness.” Sociometry (1977): 35-41.</a>{:target=“_blank“}</p>
<p>[17]: <a href="http://www.sci.unich.it/~francesc/teaching/network/closeness.html" target="_blank" rel="external">Closeness Centrality</a>{:target=“_blank“}</p>
<p>[18]: <a href="https://en.wikipedia.org/wiki/Centrality" target="_blank" rel="external">Centrality - Wikipedia</a>{:target=“_blank“}</p>
<p>[19]: <a href="http://f.wanfangdata.com.cn/download/Thesis_Y2734231.aspx" target="_blank" rel="external">姜雅文. 复杂网络社区发现若干问题研究. Diss. 北京交通大学, 2014.</a>{:target=“_blank“}</p>
<p>[20]: <a href="http://dl.acm.org/citation.cfm?id=1541882" target="_blank" rel="external">Chandola, Varun, Arindam Banerjee, and Vipin Kumar. “Anomaly detection: A survey.” ACM computing surveys (CSUR) 41.3 (2009): 15.</a>{:target=“_blank“}</p>
<p>[21]: <a href="http://dl.acm.org/citation.cfm?id=1772756" target="_blank" rel="external">Leskovec Jure, Daniel Huttenlocher, and Jon Kleinberg. “Predicting positive and negative links in online social networks.” Proceedings of the 19th international conference on World wide web. ACM, 2010.</a>{:target=“_blank“}</p>
<p>[22]: <a href="https://arxiv.org/abs/1011.4071v1" target="_blank" rel="external">Backstrom, Lars, and Jure Leskovec. “Supervised random walks: predicting and recommending links in social networks.” Proceedings of the fourth ACM international conference on Web search and data mining. ACM, 2011.</a>{:target=“_blank“}</p>
<p>[23]: <a href="http://dl.acm.org/citation.cfm?id=608330" target="_blank" rel="external">Mirza, Batul J., Benjamin J. Keller, and Naren Ramakrishnan. “Studying recommendation algorithms by graph analysis.” Journal of Intelligent Information Systems 20.2 (2003): 131-160.</a>{:target=“_blank“}</p>
<p>[24]: <a href="http://www-cs-students.stanford.edu/~taherh/papers/topic-sensitive-pagerank.pdf" target="_blank" rel="external">Haveliwala, Taher H. “Topic-sensitive pagerank.” Proceedings of the 11th international conference on World Wide Web. ACM, 2002.</a>{:target=“_blank“}</p>
<p>[25]: <a href="http://www.sciencedirect.com/science/article/pii/S0020025513003149" target="_blank" rel="external">Durand, Guillaume, Nabil Belacel, and François LaPlante. “Graph theory based model for learning path recommendation.” Information Sciences 251 (2013): 10-21.</a>{:target=“_blank“}</p>
<p>[26]: <a href="http://dl.acm.org/citation.cfm?id=2507163" target="_blank" rel="external">McAuley, Julian, and Jure Leskovec. “Hidden factors and hidden topics: understanding rating dimensions with review text.” Proceedings of the 7th ACM conference on Recommender systems. ACM, 2013.</a>{:target=“_blank“}</p>
<p>[27]: <a href="http://dl.acm.org/citation.cfm?id=2556259" target="_blank" rel="external">Yu, Xiao, et al. “Personalized entity recommendation: A heterogeneous information network approach.” Proceedings of the 7th ACM international conference on Web search and data mining. ACM, 2014.</a>{:target=“_blank“}</p>
<p>[28]: <a href="https://arxiv.org/abs/1609.08264v1" target="_blank" rel="external">Kang, Zhao, et al. “Top-N Recommendation on Graphs.” Proceedings of the 25th ACM International on Conference on Information and Knowledge Management. ACM, 2016.</a>{:target=“_blank“}</p>
<p>[29]: <a href="http://dl.acm.org/citation.cfm?id=2959185" target="_blank" rel="external">Christakopoulou, Evangelia, and George Karypis. “Local Item-Item Models For Top-N Recommendation.” Proceedings of the 10th ACM Conference on Recommender Systems. ACM, 2016.</a>{:target=“_blank“}</p>
<p>[30]: <a href="http://dl.acm.org/citation.cfm?id=2623732" target="_blank" rel="external">Perozzi, Bryan, Rami Al-Rfou, and Steven Skiena. “Deepwalk: Online learning of social representations.” Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2014.</a>{:target=“_blank“}</p>
<p>[31]: <a href="https://arxiv.org/abs/1506.05163v1" target="_blank" rel="external">Henaff, Mikael, Joan Bruna, and Yann LeCun. “Deep convolutional networks on graph-structured data.” arXiv preprint arXiv:1506.05163 (2015).</a>{:target=“_blank“}</p>
<p>[32]: <a href="https://arxiv.org/abs/1101.3291" target="_blank" rel="external">Bhagat, Smriti, Graham Cormode, and S. Muthukrishnan. “Node classification in social networks.” Social network data analytics. Springer US, 2011. 115-148.</a>{:target=“_blank“}</p>
<p>[33]: <a href="http://web.eecs.umich.edu/~dkoutra/papers/fabp_pkdd2011.pdf" target="_blank" rel="external">Koutra, Danai, et al. “Unifying guilt-by-association approaches: Theorems and fast algorithms.” Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer Berlin Heidelberg, 2011.</a>{:target=“_blank“}</p>
<p>[34]: <a href="http://dl.acm.org/citation.cfm?id=2741093" target="_blank" rel="external">Tang, Jian, et al. “Line: Large-scale information network embedding.” Proceedings of the 24th International Conference on World Wide Web. ACM, 2015.</a>{:target=“_blank“}</p>
<p>[35]: <a href="https://arxiv.org/abs/1607.00653" target="_blank" rel="external">Grover, Aditya, and Jure Leskovec. “node2vec: Scalable Feature Learning for Networks.”</a>{:target=“_blank“}</p>
<p>[36]: <a href="http://dl.acm.org/citation.cfm?id=2806512" target="_blank" rel="external">Cao, Shaosheng, Wei Lu, and Qiongkai Xu. “Grarep: Learning graph representations with global structural information.” Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. ACM, 2015.</a>{:target=“_blank“}</p>
<p>[37]: <a href="http://www.sciencedirect.com/science/article/pii/S0370157309002841" target="_blank" rel="external">Fortunato, Santo. “Community detection in graphs.” Physics reports 486.3 (2010): 75-174.</a>{:target=“_blank“}</p>
<p>[38]: <a href="http://ieeexplore.ieee.org/abstract/document/6771089/" target="_blank" rel="external">Kernighan, Brian W., and Shen Lin. “An efficient heuristic procedure for partitioning graphs.” The Bell system technical journal 49.2 (1970): 291-307.</a>{:target=“_blank“}</p>
<p>[39]: <a href="http://epubs.siam.org/doi/abs/10.1137/0603056?journalCode=sjamdu" target="_blank" rel="external">Barnes, Earl R. “An algorithm for partitioning the nodes of a graph.” SIAM Journal on Algebraic Discrete Methods 3.4 (1982): 541-550.</a>{:target=“_blank“}</p>
<p>[40]: <a href="http://dl.acm.org/citation.cfm?id=347121" target="_blank" rel="external">Flake, Gary William, Steve Lawrence, and C. Lee Giles. “Efficient identification of web communities.” Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2000.</a>{:target=“_blank“}</p>
<p>[41]: <a href="http://ieeexplore.ieee.org/abstract/document/989932/" target="_blank" rel="external">Flake, Gary William, et al. “Self-organization and identification of web communities.” Computer 35.3 (2002): 66-70.</a>{:target=“_blank“}</p>
<p>[42]: <a href="http://link.springer.com/chapter/10.1007/978-94-011-5412-3_12" target="_blank" rel="external">Pothen, Alex. “Graph partitioning algorithms with applications to scientific computing.” Parallel Numerical Algorithms. Springer Netherlands, 1997. 323-368.</a>{:target=“_blank“}</p>
<p>[43]: <a href="http://statweb.stanford.edu/~tibs/ElemStatLearn/printings/ESLII_print10.pdf" target="_blank" rel="external">Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. The elements of statistical learning. Vol. 1. Springer, Berlin: Springer series in statistics, 2001.</a>{:target=“_blank“}</p>
<p>[44]: <a href="https://projecteuclid.org/euclid.bsmsp/1200512992" target="_blank" rel="external">MacQueen, James. “Some methods for classification and analysis of multivariate observations.” Proceedings of the fifth Berkeley symposium on mathematical statistics and probability. Vol. 1. No. 14. 1967.</a>{:target=“_blank“}</p>
<p>[45]: <a href="http://www.pnas.org/content/99/12/7821.short" target="_blank" rel="external">Girvan, Michelle, and Mark EJ Newman. “Community structure in social and biological networks.” Proceedings of the national academy of sciences 99.12 (2002): 7821-7826.</a>{:target=“_blank“}</p>
<p>[46]: <a href="https://journals.aps.org/pre/abstract/10.1103/PhysRevE.69.026113" target="_blank" rel="external">Newman, Mark EJ, and Michelle Girvan. “Finding and evaluating community structure in networks.” Physical review E 69.2 (2004): 026113.</a>{:target=“_blank“}</p>
<p>[47]: <a href="http://www.cnki.com.cn/Article/CJFDTotal-JSJA201208000.htm" target="_blank" rel="external">柴变芳, 贾彩燕, and 于剑. “基于统计推理的社区发现模型综述.” 计算机科学 2012 年 08 (2012): 1-7+.</a>{:target=“_blank“}</p>
<p>[48]: <a href="http://cdmd.cnki.com.cn/Article/CDMD-10004-1015611891.htm" target="_blank" rel="external">柴变芳. 基于生成模型的大规模网络广义社区发现方法研究. Diss. 北京交通大学, 2015.</a>{:target=“_blank“}</p>
<p>[49]: <a href="http://www.mapequation.org/assets/publications/RosvallBergstromPNAS2008Full.pdf" target="_blank" rel="external">Rosvall, Martin, and Carl T. Bergstrom. “Maps of random walks on complex networks reveal community structure.” Proceedings of the National Academy of Sciences 105.4 (2008): 1118-1123.</a>{:target=“_blank“}</p>
<p>[50]: <a href="https://arxiv.org/abs/0906.1405" target="_blank" rel="external">Rosvall, Martin, Daniel Axelsson, and Carl T. Bergstrom. “The map equation.” The European Physical Journal Special Topics 178.1 (2009): 13-23.</a>{:target=“_blank“}</p>
<p>[51]: <a href="https://journals.aps.org/pre/abstract/10.1103/PhysRevE.70.066111" target="_blank" rel="external">Clauset, Aaron, Mark EJ Newman, and Cristopher Moore. “Finding community structure in very large networks.” Physical review E 70.6 (2004): 066111.</a>{:target=“_blank“}</p>
<p>[52]: <a href="https://arxiv.org/abs/0803.0476v2" target="_blank" rel="external">Blondel, Vincent D., et al. “Fast unfolding of communities in large networks.” Journal of statistical mechanics: theory and experiment 2008.10 (2008): P10008.</a>{:target=“_blank“}</p>
<p>[53]: <a href="http://bbs.pinggu.org/thread-3614747-1-1.html" target="_blank" rel="external">基于GraphX的社区发现算法FastUnfolding分布式实现</a>{:target=“_blank“}</p>
<p>[54]: <a href="http://www.pnas.org/content/103/23/8577.short" target="_blank" rel="external">Newman, Mark EJ. “Modularity and community structure in networks.” Proceedings of the national academy of sciences 103.23 (2006): 8577-8582.</a>{:target=“_blank“}</p>
<p>[55]: <a href="http://www.nature.com/nature/journal/v435/n7043/abs/nature03607.html" target="_blank" rel="external">Palla, Gergely, et al. “Uncovering the overlapping community structure of complex networks in nature and society.” Nature 435.7043 (2005): 814-818.</a>{:target=“_blank“}</p>
<p>[56]: <a href="https://github.com/rexwong/dp/wiki/%E7%A4%BE%E4%BC%9A%E8%AE%A1%E7%AE%97-%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E5%92%8C%E7%A4%BE%E4%BC%9A%E5%AA%92%E4%BD%93%E6%8C%96%E6%8E%98" target="_blank" rel="external">LeiTang, and HuanLin. 社会计算:社区发现和社会媒体挖掘. 机械工业出版社, 2013.</a>{:target=“_blank“}</p>
<p>[57]: <a href="http://iopscience.iop.org/article/10.1088/1742-5468/2005/09/P09008/meta" target="_blank" rel="external">Danon, Leon, et al. “Comparing community structure identification.” Journal of Statistical Mechanics: Theory and Experiment 2005.09 (2005): P09008.</a>{:target=“_blank“}</p>
<p>[58]: <a href="http://www.pnas.org/content/104/1/36.short" target="_blank" rel="external">Fortunato, Santo, and Marc Barthelemy. “Resolution limit in community detection.” Proceedings of the National Academy of Sciences 104.1 (2007): 36-41.</a></p>
<p>[59]: <a href="http://dl.acm.org/citation.cfm?id=1772755" target="_blank" rel="external">Leskovec, Jure, Kevin J. Lang, and Michael Mahoney. “Empirical comparison of algorithms for network community detection.” Proceedings of the 19th international conference on World wide web. ACM, 2010.</a></p>
<p>[60]: <a href="https://arxiv.org/abs/0908.1062v2" target="_blank" rel="external">Lancichinetti, Andrea, and Santo Fortunato. “Community detection algorithms: a comparative analysis.” Physical review E 80.5 (2009): 056117.</a></p>


  </article>
  </script>
    <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
  </script>
  <div class="busuanzi center">
    页阅读量:&nbsp;<span id="busuanzi_value_page_pv"></span>&nbsp;・&nbsp;
    站访问量:&nbsp;<span id="busuanzi_value_site_pv"></span>&nbsp;・&nbsp;
    站访客数:&nbsp;<span id="busuanzi_value_site_uv"></span>
  </div>


<div id="disqus_thread"></div>
<script>

var disqus_config = function () {
this.page.url = 'http://www.shesong.org/2017/02/22/复杂网络调研/index.html';
this.page.identifier = undefined;
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//shesong.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>



    </div>
  </div>
  <footer class="page-footer"><div class="clearfix">
</div>
<div class="right-foot container">
    <div class="firstrow">
        <a href="#top" target="_self">
        <i class="fa fa-arrow-right"></i>
        </a>
        © song 2016-2017
    </div>
    <div class="secondrow">
        <a href="/about">
        About me
        </a>
    </div>
</div>
<div class="clearfix">
</div>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-85091757-2', 'auto');
  ga('send', 'pageview');

</script>
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?3cef4bf23ef5935d84d349829cca2373";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
</footer>
  <script src="//cdn.bootcss.com/jquery/2.2.1/jquery.min.js"></script>
<script src="/js/search.js"></script>
<script type="text/javascript">

// disqus scripts

var disqus_shortname = 'shesong';
(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('body')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());


// dropdown scripts
$(".dropdown").click(function(event) {
  var current = $(this);
  event.stopPropagation();
  $(current).children(".dropdown-content")[($(current).children(".dropdown-content").hasClass("open"))?'removeClass':'addClass']("open")
});
$(document).click(function(){
    $(".dropdown-content").removeClass("open");
})

var path = "/search.xml";
searchFunc(path, 'local-search-input', 'local-search-result');

</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

</body>
</html>
